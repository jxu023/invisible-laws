dont' quite have a good name/title for the proj yet, should ask teammembers to think about it too

had an idea for a regex generator in the style of the excel flashfill synthesis paper

we have have it be a "general" regex generator. Given a set of execution paths of code

look through the code sequences of those paths, generate a "general" regex that would
MATCH on a majority of them or perhaps all of them.

could call it a "fuzzy" or approximate regex generator
    ***** https://laurikari.net/tre/about/ *****
we coudl then use this regex as a candidate rule
it would be a limited form of regex though to be practical i think
again, look at the excel flashfill paper and perhaps some of the other synthesis paper
for reference and examples

The other idea was to use LSA to analyze the source code to generate candidate <b> then <a> rules. I think LSA is able to rank related keywords in portions of code, lets say a document is a function or something like that. We can use the rankings from the LSA thing as input into the approximate regex generator

We coudl at least investigate the possibility of using an approximate regex generator. try to find some papers on this

also find some papers on LSA source code analysis, see how other people have used

finally, the given goal was to be able to automatically or systematically generate a code checker for code that calls some API. try to find other papers related to this and think about related ideas.

look up papers on:
    assertion generation
    lsa for source code analysis
    approximate regex generation
    checking code which calls an api / or implements an api
        example: orig paper checks
            different implementations of common filesystem interface
            device drivers implementation of interrupts

tools:
    clang static analyzer
    llvm pass

approximate regex generator might not be the exact thing i was looking for. The usage of it i had in mind is more like a trend analyzer. Given a perhaps large set of "related" execution paths, derive a very "general" regular expression that matches on most of the paths.

what if this "fuzzy regex fitting" could also be "fuzzy grammar fitting"? would it help the inference tool? make it more powerful? allow it more suggestions?

most languages are already cfg expressible, i guess cfg could be considered as having an element of time too. This case is somewhat different from the classic language cfg in that now we're considering execution path cfg. The rules shoudl apply to both of them, but execution path cfg can be more limited, it can be "straight line code" for simpler checkers can be used

we can divide the project into several parts
    internal consistency
        infer must beliefs
            direct observation
            pre and post condition
        (any optimizations over the paper?)
    code relator (common _____)
        execution path
        interface
        semantic boundary
        infer code belief across versions
        group code into equivalence classes, maybe LSA could be used here
    statistical analysis
        (on top of internal consistency, is there a better way to do this than the paper? lots of things in stats.. pgm, mcmc, need some weighted controls to favour things like local errors and such as they did in paper)
        the paper also mentions augmenting this with "code trustworthiness"
            need to segment code and evaluate "trustworthiness"
            example: old code (more trustworthy) than new code in a proj
                maybe? maybe not?
        inversion ranking
        non-spurious principle
            properties must be true for at least one element
            immediately promote may to must
        handling noise
            "there are so many paths", derive patterns, use promising ones
                aka more data
            rank error messages (from assuming MUST)
                don't rank beliefs (what did paper mean by this exactly?)
        latent specifications
            humans have specific naming conventions, datatypes, special function calls
                this is the place where LSA could be used
    candidate rule generators
        (using LSA, fuzzy regex/grammar fitting on str8 line code).

what other things can we encode about program state/belief from static analysis?

what if we could directly feed something like a boolean expression to a solver for creating our belief set?

beliefs can propagate both forward and backward, this can mean that our implementation of internal consistency is going to be a bit tricky. Well, maybe not relaly. inference of beliefs will use direct obs, pre cond, post cond. only pre cond is backwards, just collect the beliefs without flagging error is all. or maybe collect all inferred beliefs in multiple passes, flag errors in one final pass

everything declared is used at least once ..

threshold for redundancy and contradiction errors: checks separated arbitrary by ~10 executable lines at most (orig paper)

make sure to check out other papers from the orig paper's authors
make sure everyone understands everything in the orig paper
look up papers that cite orig paper and which are cited by orig paper
